import asyncio
import json
import logging
import os
import tempfile
from datetime import datetime
from typing import Optional

from aiogram import Bot, F, Router
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.types import CallbackQuery, Message
from aiogram.utils.keyboard import InlineKeyboardBuilder
from gspread.exceptions import WorksheetNotFound

from app.prompts import DEFAULT_EXTRACT_USER, DEFAULT_ROUTER_USER, EXTRACT_PROMPT_KEY, ROUTER_PROMPT_KEY
from app.handlers.delete import DeleteState, build_delete_keyboard, format_delete_list
from app.services.bot_settings_service import BotSettingsService
from app.services.delete_service import DeleteService
from app.services.intent_service import IntentService
from app.services.openai_service import OpenAIService
from app.services.qa_service import QAService
from app.services.router_service import RouterService
from app.services.sheets_service import SheetsService
from app.utils.auth import is_allowed, user_label

logger = logging.getLogger(__name__)

MAX_VOICE_SECONDS = 12 * 60
LONG_VOICE_SECONDS = 6 * 60
MAX_TRANSCRIBE_TIMEOUT = 900
MAX_TG_CHARS = 3500


class IntakeState(StatesGroup):
    waiting_required = State()


class DuplicateState(StatesGroup):
    confirming = State()


def create_voice_router(
    openai_service: OpenAIService,
    sheets_service: SheetsService,
    router_service: RouterService,
    intent_service: IntentService,
    settings_service: BotSettingsService,
    qa_service: QAService,
    delete_service: DeleteService,
    allowed_user_ids: list[int],
    allowed_usernames: list[str],
) -> Router:
    router = Router()

    @router.message(F.voice)
    async def handle_voice(message: Message, bot: Bot, state: FSMContext) -> None:
        if not is_allowed(message.from_user, allowed_user_ids, allowed_usernames):
            logger.warning("Unauthorized user: %s", user_label(message.from_user))
            await message.answer("‚õîÔ∏è –î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω.")
            return

        logger.info("–ü–æ–ª—É—á–∏–ª –∞—É–¥–∏–æ")
        status_msg = await message.answer("‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Å–æ–æ–±—â–µ–Ω–∏–µ, —ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –¥–æ –º–∏–Ω—É—Ç—ã.")
        temp_path: Optional[str] = None
        transcript = ""
        category = ""
        today_str = datetime.now().strftime("%d.%m.%Y")

        try:
            if message.voice.duration > MAX_VOICE_SECONDS:
                await status_msg.edit_text(
                    "‚ö†Ô∏è –°–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ. "
                    "–ú–∞–∫—Å–∏–º—É–º ‚Äî 12 –º–∏–Ω—É—Ç. "
                    "–†–∞–∑–±–µ–π—Ç–µ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≥–æ–ª–æ—Å–æ–≤—ã—Ö."
                )
                return

            if message.voice.duration > LONG_VOICE_SECONDS:
                minutes = max(1, round(message.voice.duration / 60))
                await status_msg.edit_text(
                    f"‚è≥ –î–ª–∏–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ ({minutes} –º–∏–Ω). "
                    "–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç."
                )

            logger.info("–°–∫–∞—á–∏–≤–∞—é –∞—É–¥–∏–æ, –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å=%ss", message.voice.duration)
            step_start = asyncio.get_running_loop().time()
            temp_path = await asyncio.wait_for(_download_voice(bot, message), timeout=30)
            file_size = os.path.getsize(temp_path)
            logger.info("–ê—É–¥–∏–æ —Å–∫–∞—á–∞–Ω–æ –∑–∞ %.2fs, —Ä–∞–∑–º–µ—Ä=%s bytes", asyncio.get_running_loop().time() - step_start, file_size)

            logger.info("–û—Ç–ø—Ä–∞–≤–ª—è—é –≤ Whisper")
            step_start = asyncio.get_running_loop().time()
            transcribe_timeout = max(180, min(MAX_TRANSCRIBE_TIMEOUT, int(message.voice.duration * 3)))
            transcript = await asyncio.wait_for(openai_service.transcribe(temp_path), timeout=transcribe_timeout)
            if not transcript:
                raise ValueError("Empty transcription")
            logger.info("–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –≥–æ—Ç–æ–≤–∞ –∑–∞ %.2fs, —Å–∏–º–≤–æ–ª–æ–≤=%s", asyncio.get_running_loop().time() - step_start, len(transcript))

            logger.info("–ß–∏—Ç–∞—é –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ—Ç–∞")
            bot_settings = await settings_service.load()
            model = bot_settings.openai_model

            logger.info("–û–ø—Ä–µ–¥–µ–ª—è—é –Ω–∞–º–µ—Ä–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
            intent = await intent_service.detect(transcript, model=model)
            action = intent.get("action", "add")
            query = intent.get("query", transcript)

            if action == "ask":
                logger.info("–†–µ–∂–∏–º –≤–æ–ø—Ä–æ—Å–∞")
                await status_msg.edit_text("‚è≥ –ò—â—É –ø–æ –±–∞–∑–µ, —ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –¥–æ –º–∏–Ω—É—Ç—ã.")
                answer = await qa_service.answer_question(query or transcript, model=model)
                await _send_long_text(status_msg, message, answer, safe_mode=bot_settings.safe_output)
                return

            if action == "delete":
                logger.info("–†–µ–∂–∏–º —É–¥–∞–ª–µ–Ω–∏—è")
                candidates = await delete_service.find_candidates(query or transcript, limit=7)
                if not candidates:
                    await status_msg.edit_text("‚ö†Ô∏è –ù–µ –Ω–∞—à–µ–ª –∑–∞–ø–∏—Å–µ–π –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è.")
                    return
                await state.set_state(DeleteState.selecting)
                await state.update_data(
                    candidates=[
                        {
                            "sheet_name": c.sheet_name,
                            "row_index": c.row_index,
                            "headers": c.headers,
                            "row_values": c.row_values,
                            "preview": c.preview,
                        }
                        for c in candidates
                    ]
                )
                kb = build_delete_keyboard(candidates)
                text = format_delete_list(candidates)
                await status_msg.edit_text(text, reply_markup=kb.as_markup())
                return

            logger.info("–ß–∏—Ç–∞—é Settings –∏–∑ Google Sheets")
            settings = await sheets_service.load_settings()
            logger.info("–ö–∞—Ç–µ–≥–æ—Ä–∏–π –Ω–∞–π–¥–µ–Ω–æ: %s", len(settings))

            logger.info("–ß–∏—Ç–∞—é –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ—Ç–∞")
            bot_settings = await settings_service.load()
            model = bot_settings.openai_model

            logger.info("–ß–∏—Ç–∞—é Prompts –∏–∑ Google Sheets")
            prompts = await sheets_service.get_prompts()
            router_prompt = prompts.get(ROUTER_PROMPT_KEY, DEFAULT_ROUTER_USER)
            extract_prompt = prompts.get(EXTRACT_PROMPT_KEY, DEFAULT_EXTRACT_USER)

            logger.info("–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é (model=%s)", model)
            category, _reasoning = await asyncio.wait_for(
                router_service.classify_category(transcript, settings, router_prompt, model=model),
                timeout=60,
            )
            logger.info("–û–ø—Ä–µ–¥–µ–ª–∏–ª –∫–∞—Ç–µ–≥–æ—Ä–∏—é: %s", category)

            logger.info("–ß–∏—Ç–∞—é –∑–∞–≥–æ–ª–æ–≤–∫–∏ –ª–∏—Å—Ç–∞: %s", category)
            headers = await sheets_service.get_headers(category)
            if not headers:
                raise ValueError("No headers found in target sheet")
            logger.info("–ù–∞—à–µ–ª —Å—Ç–æ–ª–±—Ü—ã: %s", headers)

            logger.info("–ò–∑–≤–ª–µ–∫–∞—é –¥–∞–Ω–Ω—ã–µ –ø–æ–¥ –∑–∞–≥–æ–ª–æ–≤–∫–∏ (model=%s)", model)
            clean_headers = [_clean_header(header) for header in headers]
            row = await asyncio.wait_for(
                router_service.extract_row(transcript, clean_headers, today_str, extract_prompt, model=model),
                timeout=60,
            )
            row = _apply_text_fields(headers, row, transcript)

            missing_required = _get_missing_required(headers, row)
            if missing_required:
                await state.set_state(IntakeState.waiting_required)
                await state.update_data(
                    category=category,
                    headers=headers,
                    row=row,
                    transcript=transcript,
                    today_str=today_str,
                )
                if len(missing_required) == 1 and _is_priority_header(missing_required[0][1]):
                    kb = _build_priority_keyboard()
                    await status_msg.edit_text(
                        "‚ö†Ô∏è –ù—É–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∑–∞–¥–∞—á–∏:",
                        reply_markup=kb.as_markup(),
                    )
                    return

                missing_names = ", ".join(name for _idx, name in missing_required)
                await status_msg.edit_text(
                    "‚ö†Ô∏è –ù—É–∂–Ω–æ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è:\n"
                    f"{missing_names}\n\n"
                    "–ù–∞–ø–∏—à–∏—Ç–µ –æ—Ç–≤–µ—Ç —Ç–∞–∫:\n"
                    "–ü–æ–ª–µ=–∑–Ω–∞—á–µ–Ω–∏–µ; –ü–æ–ª–µ=–∑–Ω–∞—á–µ–Ω–∏–µ\n"
                    "–ü—Ä–∏–º–µ—Ä: –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç=–í—ã—Å–æ–∫–∏–π\n\n"
                    "–ß—Ç–æ–±—ã –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å ‚Äî –Ω–∞–∂–º–∏—Ç–µ ¬´–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å¬ª –∏–ª–∏ —Å–∫–∞–∂–∏—Ç–µ ¬´off¬ª.\n"
                    "–ß—Ç–æ–±—ã –æ—Ç–º–µ–Ω–∏—Ç—å ‚Äî –Ω–∞–ø–∏—à–∏—Ç–µ ¬´–û—Ç–º–µ–Ω–∞¬ª.",
                    reply_markup=_build_required_keyboard().as_markup(),
                )
                return

            duplicate_preview = await _find_duplicate(sheets_service, category, headers, row)
            if duplicate_preview:
                await state.set_state(DuplicateState.confirming)
                await state.update_data(
                    category=category,
                    headers=headers,
                    row=row,
                    transcript=transcript,
                    today_str=today_str,
                    duplicate_preview=duplicate_preview,
                )
                await status_msg.edit_text(
                    "‚ö†Ô∏è –ü–æ—Ö–æ–∂–µ, —ç—Ç–æ –¥—É–±–ª–∏–∫–∞—Ç.\n\n"
                    f"{duplicate_preview}\n\n"
                    "–î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å?",
                    reply_markup=_build_duplicate_keyboard().as_markup(),
                )
                return

            logger.info("–ó–∞–ø–∏—Å—ã–≤–∞—é —Å—Ç—Ä–æ–∫—É –≤ –ª–∏—Å—Ç: %s", category)
            await sheets_service.append_row(category, row)
            logger.info("–ü–∏—à—É –≤ Inbox")
            await sheets_service.append_row("Inbox", [today_str, category, transcript])
            logger.info("–ó–∞–ø–∏—Å–∞–ª —Å—Ç—Ä–æ–∫—É")

            short_text = transcript if len(transcript) <= 300 else transcript[:297] + "..."
            short_text = _get_summary_value(headers, row) or short_text
            await status_msg.edit_text(
                f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ '{category}'.\n"
                f"–°—É—Ç—å: {short_text}\n"
                f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category}"
            )
        except json.JSONDecodeError:
            logger.exception("GPT returned invalid JSON")
            await status_msg.edit_text("‚ö†Ô∏è GPT –≤–µ—Ä–Ω—É–ª –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")
            await _safe_inbox(sheets_service, today_str, category or "Unknown", transcript)
        except asyncio.TimeoutError:
            logger.exception("Timeout while processing message")
            await status_msg.edit_text("‚ö†Ô∏è –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç –ò–ò. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")
            await _safe_inbox(sheets_service, today_str, category or "Unknown", transcript)
        except WorksheetNotFound:
            logger.exception("Worksheet not found")
            await status_msg.edit_text("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω –ª–∏—Å—Ç –≤ Google Sheets. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏.")
            await _safe_inbox(sheets_service, today_str, category or "Unknown", transcript)
        except Exception:
            logger.exception("Unhandled error")
            await status_msg.edit_text("‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")
            await _safe_inbox(sheets_service, today_str, category or "Unknown", transcript)
        finally:
            if temp_path:
                try:
                    os.remove(temp_path)
                except OSError:
                    logger.warning("Failed to remove temp file: %s", temp_path)

    @router.callback_query(IntakeState.waiting_required, F.data == "req:cancel")
    async def cancel_required(callback: CallbackQuery, state: FSMContext) -> None:
        if not is_allowed(callback.from_user, allowed_user_ids, allowed_usernames):
            await callback.answer("–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω", show_alert=True)
            return
        await state.clear()
        await callback.message.edit_text("–û–∫, –æ—Ç–º–µ–Ω–∏–ª.")
        await callback.answer()

    @router.callback_query(IntakeState.waiting_required, F.data == "req:skip")
    async def skip_required(callback: CallbackQuery, state: FSMContext) -> None:
        if not is_allowed(callback.from_user, allowed_user_ids, allowed_usernames):
            await callback.answer("–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω", show_alert=True)
            return

        data = await state.get_data()
        category = data.get("category", "")
        headers = data.get("headers", [])
        row = data.get("row", [])
        transcript = data.get("transcript", "")
        today_str = data.get("today_str", datetime.now().strftime("%d.%m.%Y"))

        if not category or not headers or not row:
            await state.clear()
            await callback.message.edit_text("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –∑–∞–ø–∏—Å—å.")
            await callback.answer()
            return

        duplicate_preview = await _find_duplicate(sheets_service, category, headers, row)
        if duplicate_preview:
            await state.set_state(DuplicateState.confirming)
            await state.update_data(
                category=category,
                headers=headers,
                row=row,
                transcript=transcript,
                today_str=today_str,
                duplicate_preview=duplicate_preview,
            )
            await callback.message.edit_text(
                "‚ö†Ô∏è –ü–æ—Ö–æ–∂–µ, —ç—Ç–æ –¥—É–±–ª–∏–∫–∞—Ç.\n\n"
                f"{duplicate_preview}\n\n"
                "–î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å?",
                reply_markup=_build_duplicate_keyboard().as_markup(),
            )
            await callback.answer()
            return

        row = _apply_text_fields(headers, row, transcript)
        await sheets_service.append_row(category, row)
        await sheets_service.append_row("Inbox", [today_str, category, transcript])
        await state.clear()
        short_text = transcript if len(transcript) <= 300 else transcript[:297] + "..."
        short_text = _get_summary_value(headers, row) or short_text
        await callback.message.edit_text(
            f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ '{category}' –±–µ–∑ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π.\n"
            f"–°—É—Ç—å: {short_text}\n"
            f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category}"
        )
        await callback.answer()

    @router.callback_query(IntakeState.waiting_required, F.data.startswith("req:priority:"))
    async def handle_required_priority(callback: CallbackQuery, state: FSMContext) -> None:
        if not is_allowed(callback.from_user, allowed_user_ids, allowed_usernames):
            await callback.answer("–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω", show_alert=True)
            return
        value_map = {
            "low": "–ù–∏–∑–∫–∏–π",
            "medium": "–°—Ä–µ–¥–Ω–∏–π",
            "high": "–í—ã—Å–æ–∫–∏–π",
        }
        code = callback.data.split(":")[-1]
        value = value_map.get(code)
        if not value:
            await callback.answer("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç", show_alert=True)
            return

        data = await state.get_data()
        category = data.get("category", "")
        headers = data.get("headers", [])
        row = data.get("row", [])
        transcript = data.get("transcript", "")
        today_str = data.get("today_str", datetime.now().strftime("%d.%m.%Y"))

        if not category or not headers or not row:
            await state.clear()
            await callback.message.edit_text("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –∑–∞–ø–∏—Å—å.")
            await callback.answer()
            return

        idx = None
        for i, header in enumerate(headers):
            if _is_priority_header(_display_header(header)):
                idx = i
                break
        if idx is None:
            await callback.message.edit_text("‚ö†Ô∏è –ü–æ–ª–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
            await callback.answer()
            return

        if idx < len(row):
            row[idx] = value

        missing_after = _get_missing_required(headers, row)
        if missing_after:
            missing_names = ", ".join(name for _idx, name in missing_after)
            await state.update_data(row=row)
            await callback.message.edit_text(
                "‚ö†Ô∏è –ù—É–∂–Ω–æ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è:\n"
                f"{missing_names}\n\n"
                "–ù–∞–ø–∏—à–∏—Ç–µ –æ—Ç–≤–µ—Ç —Ç–∞–∫:\n"
                "–ü–æ–ª–µ=–∑–Ω–∞—á–µ–Ω–∏–µ; –ü–æ–ª–µ=–∑–Ω–∞—á–µ–Ω–∏–µ\n"
                "–ü—Ä–∏–º–µ—Ä: –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç=–í—ã—Å–æ–∫–∏–π\n"
                "–ú–æ–∂–Ω–æ –Ω–∞–∂–∞—Ç—å ¬´–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å¬ª.",
                reply_markup=_build_required_keyboard().as_markup(),
            )
            await callback.answer()
            return

        duplicate_preview = await _find_duplicate(sheets_service, category, headers, row)
        if duplicate_preview:
            await state.set_state(DuplicateState.confirming)
            await state.update_data(
                category=category,
                headers=headers,
                row=row,
                transcript=transcript,
                today_str=today_str,
                duplicate_preview=duplicate_preview,
            )
            await callback.message.edit_text(
                "‚ö†Ô∏è –ü–æ—Ö–æ–∂–µ, —ç—Ç–æ –¥—É–±–ª–∏–∫–∞—Ç.\n\n"
                f"{duplicate_preview}\n\n"
                "–î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å?",
                reply_markup=_build_duplicate_keyboard().as_markup(),
            )
            await callback.answer()
            return

        row = _apply_text_fields(headers, row, transcript)
        await sheets_service.append_row(category, row)
        await sheets_service.append_row("Inbox", [today_str, category, transcript])
        await state.clear()
        short_text = transcript if len(transcript) <= 300 else transcript[:297] + "..."
        short_text = _get_summary_value(headers, row) or short_text
        await callback.message.edit_text(
            f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ '{category}'.\n"
            f"–°—É—Ç—å: {short_text}\n"
            f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category}"
        )
        await callback.answer()

    @router.callback_query(DuplicateState.confirming, F.data == "dup:add")
    async def confirm_duplicate_add(callback: CallbackQuery, state: FSMContext) -> None:
        if not is_allowed(callback.from_user, allowed_user_ids, allowed_usernames):
            await callback.answer("–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω", show_alert=True)
            return
        data = await state.get_data()
        category = data.get("category", "")
        headers = data.get("headers", [])
        row = data.get("row", [])
        transcript = data.get("transcript", "")
        today_str = data.get("today_str", datetime.now().strftime("%d.%m.%Y"))

        if not category or not headers or not row:
            await state.clear()
            await callback.message.edit_text("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –∑–∞–ø–∏—Å—å.")
            await callback.answer()
            return

        row = _apply_text_fields(headers, row, transcript)
        await sheets_service.append_row(category, row)
        await sheets_service.append_row("Inbox", [today_str, category, transcript])
        await state.clear()
        short_text = transcript if len(transcript) <= 300 else transcript[:297] + "..."
        short_text = _get_summary_value(headers, row) or short_text
        await callback.message.edit_text(
            f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –∫–∞–∫ –Ω–æ–≤–∞—è –∑–∞–ø–∏—Å—å –≤ '{category}'.\n"
            f"–°—É—Ç—å: {short_text}\n"
            f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category}"
        )
        await callback.answer()

    @router.callback_query(DuplicateState.confirming, F.data == "dup:skip")
    async def confirm_duplicate_skip(callback: CallbackQuery, state: FSMContext) -> None:
        if not is_allowed(callback.from_user, allowed_user_ids, allowed_usernames):
            await callback.answer("–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω", show_alert=True)
            return
        await state.clear()
        await callback.message.edit_text("–û–∫, –Ω–µ –¥–æ–±–∞–≤–ª—è—é –¥—É–±–ª–∏–∫–∞—Ç.")
        await callback.answer()

    @router.message(IntakeState.waiting_required, F.text)
    async def handle_required_fields(message: Message, state: FSMContext) -> None:
        if not is_allowed(message.from_user, allowed_user_ids, allowed_usernames):
            await message.answer("‚õîÔ∏è –î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω.")
            return

        text = message.text.strip()
        if text.lower() in {"–æ—Ç–º–µ–Ω–∞", "cancel", "—Å—Ç–æ–ø"}:
            await state.clear()
            await message.answer("–û–∫, –æ—Ç–º–µ–Ω–∏–ª.")
            return

        data = await state.get_data()
        category = data.get("category", "")
        headers = data.get("headers", [])
        row = data.get("row", [])
        transcript = data.get("transcript", "")
        today_str = data.get("today_str", datetime.now().strftime("%d.%m.%Y"))

        if not category or not headers or not row:
            await state.clear()
            await message.answer("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –∑–∞–ø–∏—Å—å.")
            return

        if text.lower() in {"off", "–ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å", "skip"}:
            row = _apply_text_fields(headers, row, transcript)
            await sheets_service.append_row(category, row)
            await sheets_service.append_row("Inbox", [today_str, category, transcript])
            await state.clear()
            short_text = transcript if len(transcript) <= 300 else transcript[:297] + "..."
            short_text = _get_summary_value(headers, row) or short_text
            await message.answer(
                f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ '{category}' –±–µ–∑ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π.\n"
                f"–°—É—Ç—å: {short_text}\n"
                f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category}"
            )
            return

        required = _get_missing_required(headers, row)
        required_map = {name.lower(): idx for idx, name in required}

        updates = _parse_key_values(text, required_map)
        if not updates and len(required) == 1:
            idx, _name = required[0]
            row[idx] = text
        else:
            for idx, value in updates.items():
                if idx < len(row):
                    row[idx] = value

        missing_after = _get_missing_required(headers, row)
        if missing_after:
            missing_names = ", ".join(name for _idx, name in missing_after)
            await message.answer(
                "‚ö†Ô∏è –ù—É–∂–Ω–æ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è:\n"
                f"{missing_names}\n\n"
                "–ù–∞–ø–∏—à–∏—Ç–µ –æ—Ç–≤–µ—Ç —Ç–∞–∫:\n"
                "–ü–æ–ª–µ=–∑–Ω–∞—á–µ–Ω–∏–µ; –ü–æ–ª–µ=–∑–Ω–∞—á–µ–Ω–∏–µ\n"
                "–ü—Ä–∏–º–µ—Ä: –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç=–í—ã—Å–æ–∫–∏–π\n"
                "–ú–æ–∂–Ω–æ –Ω–∞–ø–∏—Å–∞—Ç—å ¬´off¬ª –∏–ª–∏ ¬´–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å¬ª."
            )
            await state.update_data(row=row)
            return

        duplicate_preview = await _find_duplicate(sheets_service, category, headers, row)
        if duplicate_preview:
            await state.set_state(DuplicateState.confirming)
            await state.update_data(
                category=category,
                headers=headers,
                row=row,
                transcript=transcript,
                today_str=today_str,
                duplicate_preview=duplicate_preview,
            )
            await message.answer(
                "‚ö†Ô∏è –ü–æ—Ö–æ–∂–µ, —ç—Ç–æ –¥—É–±–ª–∏–∫–∞—Ç.\n\n"
                f"{duplicate_preview}\n\n"
                "–î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å?",
                reply_markup=_build_duplicate_keyboard().as_markup(),
            )
            return

        row = _apply_text_fields(headers, row, transcript)
        await sheets_service.append_row(category, row)
        await sheets_service.append_row("Inbox", [today_str, category, transcript])
        await state.clear()

        short_text = transcript if len(transcript) <= 300 else transcript[:297] + "..."
        short_text = _get_summary_value(headers, row) or short_text
        await message.answer(
            f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ '{category}'.\n"
            f"–°—É—Ç—å: {short_text}\n"
            f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category}"
        )

    return router


async def _download_voice(bot: Bot, message: Message) -> str:
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".ogg")
    temp_path = temp_file.name
    temp_file.close()

    file = await bot.get_file(message.voice.file_id)
    await bot.download_file(file.file_path, destination=temp_path)
    return temp_path


async def _safe_inbox(
    sheets_service: SheetsService,
    today_str: str,
    category: str,
    transcript: str,
) -> None:
    if not transcript:
        return
    try:
        await sheets_service.append_row("Inbox", [today_str, category, transcript])
    except Exception:
        logger.exception("Failed to write to Inbox")


def _get_missing_required(headers: list[str], row: list[str]) -> list[tuple[int, str]]:
    missing = []
    for idx, header in enumerate(headers):
        if header.strip().endswith("*"):
            value = row[idx] if idx < len(row) else ""
            if not str(value).strip():
                missing.append((idx, _display_header(header)))
    return missing


def _display_header(header: str) -> str:
    return header.replace("*", "").strip()


def _clean_header(header: str) -> str:
    return header.replace("*", "").strip()


def _parse_key_values(text: str, header_map: dict[str, int]) -> dict[int, str]:
    result: dict[int, str] = {}
    parts = [part.strip() for part in text.split(";") if part.strip()]
    lines = []
    for part in parts:
        lines.extend([line.strip() for line in part.split("\n") if line.strip()])

    for line in lines:
        if ":" in line:
            key, value = line.split(":", 1)
        elif "=" in line:
            key, value = line.split("=", 1)
        elif " - " in line:
            key, value = line.split(" - ", 1)
        else:
            continue
        key_norm = _display_header(key).lower()
        if key_norm in header_map:
            result[header_map[key_norm]] = value.strip()

    return result


def _apply_text_fields(headers: list[str], row: list[str], transcript: str) -> list[str]:
    raw_idx = _find_header_index(headers, {"—Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç", "raw text", "original text", "–∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç"})
    summary_idx = _find_header_index(headers, {"—Å—É—Ç—å", "–æ–ø–∏—Å–∞–Ω–∏–µ", "summary"})

    if raw_idx is not None and raw_idx < len(row):
        row[raw_idx] = transcript

    if summary_idx is not None and summary_idx < len(row):
        summary_value = str(row[summary_idx]).strip()
        raw_value = transcript.strip()
        raw_col_value = ""
        if raw_idx is not None and raw_idx < len(row):
            raw_col_value = str(row[raw_idx]).strip()

        if (
            not summary_value
            or _normalize_text(summary_value) == _normalize_text(raw_value)
            or _normalize_text(summary_value) == _normalize_text(raw_col_value)
        ):
            row[summary_idx] = _make_summary(transcript)

    return row


def _get_summary_value(headers: list[str], row: list[str]) -> str:
    idx = _find_header_index(headers, {"—Å—É—Ç—å", "–æ–ø–∏—Å–∞–Ω–∏–µ", "summary"})
    if idx is None or idx >= len(row):
        return ""
    return str(row[idx]).strip()


async def _find_duplicate(
    sheets_service: SheetsService,
    category: str,
    headers: list[str],
    row: list[str],
    limit: int = 50,
) -> str | None:
    try:
        rows = await sheets_service.get_all_values(category)
    except Exception:
        logger.exception("Failed to read sheet for duplicate check: %s", category)
        return None

    if not rows or len(rows) < 2:
        return None

    header_row = rows[0]
    summary_new = _get_value_by_headers(headers, row, {"—Å—É—Ç—å", "–æ–ø–∏—Å–∞–Ω–∏–µ", "summary"})
    raw_new = _get_value_by_headers(headers, row, {"—Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç", "raw text", "original text", "–∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç"})
    date_new = _get_value_by_headers(headers, row, {"–¥–∞—Ç–∞", "–¥–∞—Ç–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è", "–¥–∞—Ç–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è", "date"})

    recent_rows = rows[1:][-limit:]
    for old in reversed(recent_rows):
        summary_old = _get_value_by_headers(header_row, old, {"—Å—É—Ç—å", "–æ–ø–∏—Å–∞–Ω–∏–µ", "summary"})
        raw_old = _get_value_by_headers(header_row, old, {"—Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç", "raw text", "original text", "–∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç"})
        date_old = _get_value_by_headers(header_row, old, {"–¥–∞—Ç–∞", "–¥–∞—Ç–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è", "–¥–∞—Ç–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è", "date"})

        if _is_duplicate(summary_new, raw_new, date_new, summary_old, raw_old, date_old):
            return _format_duplicate_preview(header_row, old)

    return None


def _is_duplicate(
    summary_new: str,
    raw_new: str,
    date_new: str,
    summary_old: str,
    raw_old: str,
    date_old: str,
) -> bool:
    if summary_new and summary_old and _normalize_text(summary_new) == _normalize_text(summary_old):
        return _same_or_empty(date_new, date_old)
    if raw_new and raw_old and _normalize_text(raw_new) == _normalize_text(raw_old):
        return _same_or_empty(date_new, date_old)
    return False


def _same_or_empty(left: str, right: str) -> bool:
    if not left or not right:
        return True
    return _normalize_text(left) == _normalize_text(right)


def _get_value_by_headers(headers: list[str], row: list[str], names: set[str]) -> str:
    idx = _find_header_index(headers, names)
    if idx is None or idx >= len(row):
        return ""
    return str(row[idx]).strip()


def _format_duplicate_preview(headers: list[str], row: list[str]) -> str:
    date_value = _get_value_by_headers(headers, row, {"–¥–∞—Ç–∞", "–¥–∞—Ç–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è", "–¥–∞—Ç–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è", "date"})
    summary_value = _get_value_by_headers(headers, row, {"—Å—É—Ç—å", "–æ–ø–∏—Å–∞–Ω–∏–µ", "summary", "–Ω–∞ —á—Ç–æ –ø–æ—Ç—Ä–∞—á–µ–Ω–æ"})
    raw_value = _get_value_by_headers(headers, row, {"—Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç", "raw text", "original text", "–∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç"})

    lines = []
    if date_value:
        lines.append(f"üìÖ –î–∞—Ç–∞: {_shorten(date_value)}")
    if summary_value:
        lines.append(f"üìù –°—É—Ç—å: {_shorten(summary_value)}")
    if raw_value and _normalize_text(raw_value) != _normalize_text(summary_value):
        lines.append(f"üó£Ô∏è –°—ã—Ä–æ–π —Ç–µ–∫—Å—Ç: {_shorten(raw_value, 120)}")
    return "\n".join(lines) if lines else "–ü–æ—Ö–æ–∂–∞—è –∑–∞–ø–∏—Å—å –Ω–∞–π–¥–µ–Ω–∞."


def _shorten(value: str, limit: int = 80) -> str:
    value = value.strip()
    if len(value) <= limit:
        return value
    return value[: limit - 3].rstrip() + "..."


def _find_header_index(headers: list[str], names: set[str]) -> int | None:
    for idx, header in enumerate(headers):
        header_norm = _display_header(header).lower().strip()
        if header_norm in names:
            return idx
    return None


def _normalize_text(value: str) -> str:
    return " ".join(value.lower().split())


def _make_summary(text: str) -> str:
    summary = text.strip()
    if not summary:
        return summary

    prefixes = [
        "—Å–ª—É—à–∞–π",
        "–∞ —Å–ª—É—à–∞–π",
        "–º–Ω–µ –Ω–∞–¥–æ",
        "–º–Ω–µ –Ω—É–∂–Ω–æ",
        "–Ω—É–∂–Ω–æ",
        "—è —Ö–æ—á—É",
        "—Ö–æ—á—É",
        "–º–æ–∂–µ—à—å",
        "–º–æ–∂–µ—à—å –ø–æ–∂–∞–ª—É–π—Å—Ç–∞",
        "–ø–æ–∂–∞–ª—É–π—Å—Ç–∞",
        "–Ω–∞–¥–æ",
    ]
    changed = True
    while changed:
        changed = False
        lowered = summary.lower().lstrip()
        for pref in prefixes:
            if lowered.startswith(pref):
                summary = summary[len(pref):].lstrip(" ,.-")
                changed = True
                break

    suffixes = [
        "–º–æ–∂–µ—à—å –ø–æ—Å—Ç–∞–≤–∏—Ç—å –∑–∞–¥–∞—á–∫—É",
        "–º–æ–∂–µ—à—å –ø–æ—Å—Ç–∞–≤–∏—Ç—å –∑–∞–¥–∞—á—É",
        "–ø–æ—Å—Ç–∞–≤—å –∑–∞–¥–∞—á–∫—É",
        "–ø–æ—Å—Ç–∞–≤—å –∑–∞–¥–∞—á—É",
        "–¥–æ–±–∞–≤—å –≤ –∑–∞–¥–∞—á–∏",
        "–¥–æ–±–∞–≤—å –∑–∞–¥–∞—á—É",
        "–∑–∞–ø–æ–º–Ω–∏ —ç—Ç–æ",
        "–ø–æ–∂–∞–ª—É–π—Å—Ç–∞",
    ]
    lowered = summary.lower()
    for suf in suffixes:
        if lowered.endswith(suf):
            summary = summary[: -len(suf)].rstrip(" ,.-")
            break

    summary = " ".join(summary.split())
    if len(summary) > 160:
        summary = summary[:157].rstrip() + "..."
    return summary or text


def _is_priority_header(header: str) -> bool:
    return "–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç" in header.strip().lower()


def _build_priority_keyboard() -> InlineKeyboardBuilder:
    kb = InlineKeyboardBuilder()
    kb.button(text="–ù–∏–∑–∫–∏–π", callback_data="req:priority:low")
    kb.button(text="–°—Ä–µ–¥–Ω–∏–π", callback_data="req:priority:medium")
    kb.button(text="–í—ã—Å–æ–∫–∏–π", callback_data="req:priority:high")
    kb.button(text="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å", callback_data="req:skip")
    kb.button(text="–û—Ç–º–µ–Ω–∞", callback_data="req:cancel")
    kb.adjust(3, 1, 1)
    return kb


def _build_required_keyboard() -> InlineKeyboardBuilder:
    kb = InlineKeyboardBuilder()
    kb.button(text="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å", callback_data="req:skip")
    kb.button(text="–û—Ç–º–µ–Ω–∞", callback_data="req:cancel")
    kb.adjust(2)
    return kb


def _build_duplicate_keyboard() -> InlineKeyboardBuilder:
    kb = InlineKeyboardBuilder()
    kb.button(text="‚úÖ –î–æ–±–∞–≤–∏—Ç—å", callback_data="dup:add")
    kb.button(text="‚ùå –ù–µ –¥–æ–±–∞–≤–ª—è—Ç—å", callback_data="dup:skip")
    kb.adjust(2)
    return kb


async def _send_long_text(
    status_msg: Message,
    message: Message,
    text: str,
    safe_mode: bool = True,
) -> None:
    chunks = _split_text(text, MAX_TG_CHARS)
    if not chunks:
        return
    if safe_mode and len(chunks) > 3:
        chunks = chunks[:3]
        chunks[-1] = (
            chunks[-1]
            + "\n\n‚Ä¶–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤. –£—Ç–æ—á–Ω–∏—Ç–µ –∑–∞–ø—Ä–æ—Å."
        )
    try:
        await status_msg.edit_text(chunks[0])
    except Exception:
        await message.answer(chunks[0])
    for chunk in chunks[1:]:
        await message.answer(chunk)


def _split_text(text: str, max_len: int) -> list[str]:
    text = text.strip()
    if len(text) <= max_len:
        return [text]
    chunks: list[str] = []
    current: list[str] = []
    current_len = 0
    for line in text.splitlines():
        line_len = len(line) + 1
        if line_len > max_len:
            if current:
                chunks.append("\n".join(current).strip())
                current = []
                current_len = 0
            for i in range(0, len(line), max_len):
                chunks.append(line[i : i + max_len])
            continue
        if current_len + line_len > max_len and current:
            chunks.append("\n".join(current).strip())
            current = [line]
            current_len = line_len
        else:
            current.append(line)
            current_len += line_len
    if current:
        chunks.append("\n".join(current).strip())
    return [chunk for chunk in chunks if chunk]
